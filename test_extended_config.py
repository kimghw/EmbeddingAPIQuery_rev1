"""
Extended configuration test for upload and chunking settings.
"""

import os
import asyncio
from config.settings import ConfigAdapter, TestConfig, create_config
from config.adapter_factory import DependencyContainer


async def test_extended_config():
    """Test extended configuration including upload and chunking settings."""
    print("=== í™•ì¥ëœ ì„¤ì • í…ŒìŠ¤íŠ¸ ===")
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì • ìƒì„±
    config = ConfigAdapter(TestConfig())
    
    # ê¸°ë³¸ ì„¤ì • í™•ì¸
    print(f"ì•± ì´ë¦„: {config.get_app_name()}")
    print(f"ë””ë²„ê·¸ ëª¨ë“œ: {config.get_debug()}")
    print(f"ë¡œê·¸ ë ˆë²¨: {config.get_log_level()}")
    
    # ì˜ì¡´ì„± ì£¼ì… ì„¤ì • í™•ì¸
    print(f"\n=== ì˜ì¡´ì„± ì£¼ì… ì„¤ì • ===")
    print(f"ë²¡í„° ì €ì¥ì†Œ íƒ€ì…: {config.get_vector_store_type()}")
    print(f"ì„ë² ë”© íƒ€ì…: {config.get_embedding_type()}")
    print(f"ë¬¸ì„œ ë¡œë” íƒ€ì…: {config.get_document_loader_type()}")
    print(f"í…ìŠ¤íŠ¸ ì²­í‚¹ íƒ€ì…: {config.get_text_chunker_type()}")
    print(f"ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì…: {config.get_retriever_type()}")
    
    # LLM ì„¤ì • í™•ì¸
    print(f"\n=== LLM ì„¤ì • ===")
    print(f"LLM ëª¨ë¸ íƒ€ì…: {config.get_llm_model_type()}")
    print(f"LLM ëª¨ë¸ëª…: {config.get_llm_model_name()}")
    print(f"LLM ì˜¨ë„: {config.get_llm_temperature()}")
    print(f"LLM ìµœëŒ€ í† í°: {config.get_llm_max_tokens()}")
    
    # ì—…ë¡œë“œ ì„¤ì • í™•ì¸
    print(f"\n=== ì—…ë¡œë“œ ì„¤ì • ===")
    print(f"ìµœëŒ€ íŒŒì¼ í¬ê¸°: {config.get_upload_max_file_size():,} bytes")
    print(f"í—ˆìš© í™•ì¥ì: {config.get_upload_allowed_extensions()}")
    print(f"ì—…ë¡œë“œ ë””ë ‰í† ë¦¬: {config.get_upload_directory()}")
    print(f"ì„ì‹œ ë””ë ‰í† ë¦¬: {config.get_upload_temp_directory()}")
    
    # ê³ ê¸‰ ì²­í‚¹ ì„¤ì • í™•ì¸
    print(f"\n=== ê³ ê¸‰ ì²­í‚¹ ì„¤ì • ===")
    print(f"ì‹œë§¨í‹± ì²­í¬ ìµœì†Œ í¬ê¸°: {config.get_semantic_chunk_min_size()}")
    print(f"ì‹œë§¨í‹± ì²­í¬ ìµœëŒ€ í¬ê¸°: {config.get_semantic_chunk_max_size()}")
    print(f"ì‹œë§¨í‹± ìœ ì‚¬ë„ ì„ê³„ê°’: {config.get_semantic_similarity_threshold()}")
    
    # ê²€ìƒ‰ ì„¤ì • í™•ì¸
    print(f"\n=== ê²€ìƒ‰ ì„¤ì • ===")
    print(f"ê²€ìƒ‰ Top-K: {config.get_retrieval_top_k()}")
    print(f"ì ìˆ˜ ì„ê³„ê°’: {config.get_retrieval_score_threshold()}")
    
    # ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • í™•ì¸
    print(f"\n=== ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • ===")
    print(f"ì•™ìƒë¸” ê°€ì¤‘ì¹˜: {config.get_ensemble_weights()}")
    print(f"ê²€ìƒ‰ íƒ€ì…: {config.get_ensemble_search_types()}")
    
    # ì˜ì¡´ì„± ì»¨í…Œì´ë„ˆ í…ŒìŠ¤íŠ¸
    print(f"\n=== ì˜ì¡´ì„± ì»¨í…Œì´ë„ˆ í…ŒìŠ¤íŠ¸ ===")
    container = DependencyContainer(config)
    
    # ëª¨ë“  ì–´ëŒ‘í„° ìƒì„± í…ŒìŠ¤íŠ¸
    try:
        vector_store = container.vector_store
        print(f"âœ… ë²¡í„° ì €ì¥ì†Œ: {type(vector_store).__name__}")
        
        embedding = container.embedding_model
        print(f"âœ… ì„ë² ë”© ëª¨ë¸: {type(embedding).__name__}")
        
        document_loader = container.document_loader
        print(f"âœ… ë¬¸ì„œ ë¡œë”: {type(document_loader).__name__}")
        
        text_chunker = container.text_chunker
        print(f"âœ… í…ìŠ¤íŠ¸ ì²­í‚¹: {type(text_chunker).__name__}")
        
        retriever = container.retriever
        print(f"âœ… ë¦¬íŠ¸ë¦¬ë²„: {type(retriever).__name__}")
        
        print("âœ… ëª¨ë“  ì–´ëŒ‘í„° ìƒì„± ì„±ê³µ")
        
    except Exception as e:
        print(f"âŒ ì–´ëŒ‘í„° ìƒì„± ì‹¤íŒ¨: {e}")
        return False
    
    # í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì • ë³€ê²½ í…ŒìŠ¤íŠ¸
    print(f"\n=== í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë³€ê²½ í…ŒìŠ¤íŠ¸ ===")
    
    # ì—…ë¡œë“œ ì„¤ì • ë³€ê²½
    os.environ["UPLOAD_MAX_FILE_SIZE"] = "104857600"  # 100MB
    os.environ["UPLOAD_ALLOWED_EXTENSIONS"] = "pdf,txt,docx,pptx"
    os.environ["UPLOAD_DIRECTORY"] = "custom_uploads"
    
    # ì²­í‚¹ ì„¤ì • ë³€ê²½
    os.environ["SEMANTIC_CHUNK_MIN_SIZE"] = "200"
    os.environ["SEMANTIC_CHUNK_MAX_SIZE"] = "1500"
    os.environ["SEMANTIC_SIMILARITY_THRESHOLD"] = "0.75"
    
    # ê²€ìƒ‰ ì„¤ì • ë³€ê²½
    os.environ["RETRIEVAL_TOP_K"] = "10"
    os.environ["RETRIEVAL_SCORE_THRESHOLD"] = "0.8"
    
    # ì•™ìƒë¸” ì„¤ì • ë³€ê²½
    os.environ["ENSEMBLE_WEIGHTS"] = "0.7,0.3"
    os.environ["ENSEMBLE_SEARCH_TYPES"] = "similarity,similarity_score_threshold"
    
    # ìƒˆë¡œìš´ ì„¤ì •ìœ¼ë¡œ ì»¨í…Œì´ë„ˆ ìƒì„± (ê¸°ì¡´ ì»¨í…Œì´ë„ˆëŠ” ê¸°ì¡´ ì„¤ì •ì„ ìœ ì§€í•˜ë¯€ë¡œ)
    new_config = create_config()
    new_container = DependencyContainer(new_config)
    
    print(f"ë³€ê²½ëœ ìµœëŒ€ íŒŒì¼ í¬ê¸°: {new_config.get_upload_max_file_size():,} bytes")
    print(f"ë³€ê²½ëœ í—ˆìš© í™•ì¥ì: {new_config.get_upload_allowed_extensions()}")
    print(f"ë³€ê²½ëœ ì—…ë¡œë“œ ë””ë ‰í† ë¦¬: {new_config.get_upload_directory()}")
    print(f"ë³€ê²½ëœ ì‹œë§¨í‹± ì²­í¬ ìµœì†Œ í¬ê¸°: {new_config.get_semantic_chunk_min_size()}")
    print(f"ë³€ê²½ëœ ì‹œë§¨í‹± ì²­í¬ ìµœëŒ€ í¬ê¸°: {new_config.get_semantic_chunk_max_size()}")
    print(f"ë³€ê²½ëœ ì‹œë§¨í‹± ìœ ì‚¬ë„ ì„ê³„ê°’: {new_config.get_semantic_similarity_threshold()}")
    print(f"ë³€ê²½ëœ ê²€ìƒ‰ Top-K: {new_config.get_retrieval_top_k()}")
    print(f"ë³€ê²½ëœ ì ìˆ˜ ì„ê³„ê°’: {new_config.get_retrieval_score_threshold()}")
    print(f"ë³€ê²½ëœ ì•™ìƒë¸” ê°€ì¤‘ì¹˜: {new_config.get_ensemble_weights()}")
    print(f"ë³€ê²½ëœ ê²€ìƒ‰ íƒ€ì…: {new_config.get_ensemble_search_types()}")
    
    # í™˜ê²½ ë³€ìˆ˜ ì •ë¦¬
    env_vars_to_clean = [
        "UPLOAD_MAX_FILE_SIZE", "UPLOAD_ALLOWED_EXTENSIONS", "UPLOAD_DIRECTORY",
        "SEMANTIC_CHUNK_MIN_SIZE", "SEMANTIC_CHUNK_MAX_SIZE", "SEMANTIC_SIMILARITY_THRESHOLD",
        "RETRIEVAL_TOP_K", "RETRIEVAL_SCORE_THRESHOLD",
        "ENSEMBLE_WEIGHTS", "ENSEMBLE_SEARCH_TYPES"
    ]
    
    for var in env_vars_to_clean:
        if var in os.environ:
            del os.environ[var]
    
    print("âœ… í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë³€ê²½ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    # ì–´ëŒ‘í„° íƒ€ì… ì „í™˜ í…ŒìŠ¤íŠ¸
    print(f"\n=== ì–´ëŒ‘í„° íƒ€ì… ì „í™˜ í…ŒìŠ¤íŠ¸ ===")
    
    # ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ensembleë¡œ ë³€ê²½
    os.environ["RETRIEVER_TYPE"] = "ensemble"
    ensemble_config = create_config()
    ensemble_container = DependencyContainer(ensemble_config)
    
    try:
        ensemble_retriever = ensemble_container.retriever
        print(f"âœ… ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±: {type(ensemble_retriever).__name__}")
    except Exception as e:
        print(f"âŒ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # í…ìŠ¤íŠ¸ ì²­í‚¹ì„ semanticìœ¼ë¡œ ë³€ê²½
    os.environ["TEXT_CHUNKER_TYPE"] = "semantic"
    semantic_config = create_config()
    semantic_container = DependencyContainer(semantic_config)
    
    try:
        semantic_chunker = semantic_container.text_chunker
        print(f"âœ… ì‹œë§¨í‹± ì²­í‚¹ ìƒì„±: {type(semantic_chunker).__name__}")
    except Exception as e:
        print(f"âŒ ì‹œë§¨í‹± ì²­í‚¹ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # í™˜ê²½ ë³€ìˆ˜ ì •ë¦¬
    if "RETRIEVER_TYPE" in os.environ:
        del os.environ["RETRIEVER_TYPE"]
    if "TEXT_CHUNKER_TYPE" in os.environ:
        del os.environ["TEXT_CHUNKER_TYPE"]
    
    print("âœ… ì–´ëŒ‘í„° íƒ€ì… ì „í™˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    # JSON ë¡œë” í…ŒìŠ¤íŠ¸
    print(f"\n=== JSON ë¡œë” í…ŒìŠ¤íŠ¸ ===")
    
    os.environ["DOCUMENT_LOADER_TYPE"] = "json"
    json_config = create_config()
    json_container = DependencyContainer(json_config)
    
    try:
        json_loader = json_container.document_loader
        print(f"âœ… JSON ë¡œë” ìƒì„±: {type(json_loader).__name__}")
    except Exception as e:
        print(f"âŒ JSON ë¡œë” ìƒì„± ì‹¤íŒ¨: {e}")
    
    # í™˜ê²½ ë³€ìˆ˜ ì •ë¦¬
    if "DOCUMENT_LOADER_TYPE" in os.environ:
        del os.environ["DOCUMENT_LOADER_TYPE"]
    
    print("âœ… JSON ë¡œë” í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    print("\nğŸ‰ ëª¨ë“  í™•ì¥ëœ ì„¤ì • í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return True


if __name__ == "__main__":
    asyncio.run(test_extended_config())
